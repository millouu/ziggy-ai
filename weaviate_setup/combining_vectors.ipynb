{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import CLIPProcessor, CLIPModel, SegformerImageProcessor, AutoModelForSemanticSegmentation , AutoFeatureExtractor\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from weaviate.util import generate_uuid5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import weaviate \n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "from time import sleep\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"patrickjohncyh/fashion-clip\"\n",
    "model = CLIPModel.from_pretrained(checkpoint)\n",
    "processor = CLIPProcessor.from_pretrained(checkpoint)\n",
    "seg_processor = SegformerImageProcessor.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "seg_model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "\n",
    "def getTextEmbeddings(text):\n",
    "\tinputs = processor(text=text , images=Image.new('RGB' , (72 , 72)), return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"text_embeds\"]\n",
    "\n",
    "def getImageEmbeddingsFromPath(image_path):\n",
    "\timage = Image.open(image_path)\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\t\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def getImageEmbeddings(image):\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def applyMask(image, mask):\n",
    "\timage = np.array(image)\n",
    "\tmask = np.array(mask)\n",
    "\tmask = np.stack((mask,)*3, axis=-1)\n",
    "\tresultant = image*mask\n",
    "\tresultant[mask == 0] = 255\n",
    "\treturn resultant\n",
    "\n",
    "def cropImage(image):\n",
    "\ttemp = image[:, :, ::-1].copy() \n",
    "\ttemp = temp.astype('uint8')\n",
    "\tgray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "\tthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\tcontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\tcontours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\tx,y,w,h = cv2.boundingRect(contours[0])\n",
    "\tcrop = image[y:y+h, x:x+w]\n",
    "\treturn crop\n",
    "\n",
    "def segment(image, to_mask):\n",
    "\tinputs = seg_processor(images=image, return_tensors=\"pt\")\n",
    "\toutputs = seg_model(**inputs)\n",
    "\tlogits = outputs.logits.cpu()\n",
    "\tupsampled_logits = nn.functional.interpolate(\n",
    "\t\tlogits,\n",
    "\t\tsize=image.size[::-1],\n",
    "\t\tmode=\"bilinear\",\n",
    "\t\talign_corners=False,\n",
    "\t)\n",
    "\tpred_seg = upsampled_logits.argmax(dim=1)[0]\n",
    "\tresult = []\n",
    "\tfor i in to_mask:\n",
    "\t\tmask = pred_seg.numpy().copy()\n",
    "\t\tmask[mask != i] = 0\n",
    "\t\tmask[mask == i] = 1\n",
    "\t\titem = applyMask(image, mask)\n",
    "\t\tresult.append(item)\n",
    "\treturn result\n",
    "\n",
    "def segmentAndEmbed(image_path, to_mask):\n",
    "\tresult = {}\n",
    "\timage = Image.open(image_path)\n",
    "\tfullImageEmbedding = getImageEmbeddings(image)\n",
    "\tbuffered = BytesIO()\n",
    "\timage.save(buffered, format=\"PNG\")\n",
    "\tfullImageBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\tresult[\"fullImageBase64\"] = fullImageBase64\n",
    "\tresult[\"fullImageEmbedding\"] = fullImageEmbedding\n",
    "\tsegments = segment(image, to_mask)\n",
    "\tfor i in range(len(to_mask)):\n",
    "\t\tsegmentEmbedding = getImageEmbeddings(segments[i])\n",
    "\t\tsegments[i] = Image.fromarray(np.uint8(segments[i]))\n",
    "\t\tbuffered = BytesIO()\n",
    "\t\tsegments[i].save(buffered, format=\"PNG\")\n",
    "\t\tsegmentBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\t\tresult[f\"segmentBase64_{i}\"] = segmentBase64\n",
    "\t\tresult[f\"segmentEmbedding_{i}\"] = segmentEmbedding\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(vector_list):\n",
    "    vectors_array = np.array(vector_list)\n",
    "    max_pooled_vector = np.max(vectors_array, axis=0) \n",
    "    return max_pooled_vector\n",
    "\n",
    "def mean_pooling(vector_list):\n",
    "    vectors_array = np.array(vector_list)\n",
    "    mean_pooled_vector = np.mean(vectors_array, axis=0)\n",
    "    return mean_pooled_vector\n",
    "\n",
    "def weighted_mean_pooling(vector_list, weight_list):\n",
    "    vectors_array = np.array(vector_list)\n",
    "    weights_array = np.array(weight_list)\n",
    "    weighted_sum = np.sum(vectors_array * weights_array[:, np.newaxis], axis=0)\n",
    "    sum_of_weights = np.sum(weights_array)\n",
    "    weighted_mean = weighted_sum / sum_of_weights\n",
    "    return weighted_mean\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    vector1 = np.array(vector1)\n",
    "    vector1 = vector1.reshape(1, -1)\n",
    "    vector2 = np.array(vector2)\n",
    "    vector2 = vector2.reshape(-1, 1)\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(url=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = getTextEmbeddings(\"all white outfit with white top and white pants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_filter1 = {\n",
    "    \"path\" : [\"category\"],\n",
    "    \"operator\" : \"Like\",\n",
    "    \"valueText\" : \"girls\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = (\n",
    "    client.query\n",
    "    # .get(\"FlipkartProducts\",[\"uRL\", \"brand\", \"category\", \"product\", \"price\", \"rating\", \"numberRatings\", \"colour\", \"row\"])\n",
    "    .get(\"PinterestImages\", [\"image\", \"top {... on PinterestTop { image, _additional {vector} }}\"])\n",
    "    .with_near_vector({\"vector\" : embeddings.tolist()[0]})\n",
    "    .with_where(where_filter1)\n",
    "    # .with_near_vector({\"vector\" : top_embedding})\n",
    "    .with_additional([\"vector\", \"id\", \"distance\"])\n",
    "    .with_limit(5)\n",
    "    .do()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response1[\"data\"][\"Get\"][\"PinterestImages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    try:\n",
    "        # image = response[\"data\"][\"Get\"][\"FlipkartProducts\"][i]['image']\n",
    "        # image = response1[\"data\"][\"Get\"][\"PinterestImages\"][i][\"top\"][0]['image']\n",
    "        image = response1[\"data\"][\"Get\"][\"PinterestImages\"][i]['image']\n",
    "        image = Image.open(BytesIO(base64.b64decode(image.split(\",\",1)[0])))\n",
    "        image.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_embeddings = []\n",
    "for i in range(len(response1[\"data\"][\"Get\"][\"PinterestImages\"])):\n",
    "    top_embedding = response1[\"data\"][\"Get\"][\"PinterestImages\"][i][\"top\"][0]['_additional'][\"vector\"]\n",
    "    list_of_embeddings.append(top_embedding)\n",
    "\n",
    "list_of_embeddings.append(embeddings.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.07, 0.07, 0.07, 0.07, 0.07, 0.65]\n",
    "# weights = [0.2, 0.15, 0.15, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mean = mean_pooling(list_of_embeddings).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_weighted_mean = weighted_mean_pooling(list_of_embeddings, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_filter = {\n",
    "    \"path\": [\"category\"],\n",
    "    \"operator\": \"Like\",\n",
    "    \"valueText\" : \"Girls\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    client.query\n",
    "    .get(\"FlipkartNoSegProducts\",[\"uRL\", \"brand\", \"category\", \"product\", \"price\", \"rating\", \"numberRatings\", \"colour\", \"brand\", \"image\", \"fit\", \"type\"])\n",
    "    .with_near_vector({\"vector\" : top_weighted_mean})\n",
    "    .with_additional([\"vector\", \"id\", \"distance\"])\n",
    "    .with_limit(12)\n",
    "    .do()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_based_rank(original_vector, products):\n",
    "    product_text_embeddings = {}\n",
    "    for i, product in enumerate(products):\n",
    "        product_text_embedding = getTextEmbeddings(f\"Name: {product['product']}, Color: {product['colour']}, Fit: {product['fit']}, Type: {product['type']}\")\n",
    "        product_text_embeddings[i] = product_text_embedding.tolist()[0]\n",
    "    cosine_similarities = {}\n",
    "    for i, embedding in product_text_embeddings.items():\n",
    "        cosine_similarities[i] = cosine_similarity(original_vector, embedding).tolist()[0][0]\n",
    "    cosine_similarity_ranking = sorted(cosine_similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    rank_tuples = []\n",
    "    for i, (rank, _) in enumerate(cosine_similarity_ranking):\n",
    "        rank_tuples.append((i, rank))\n",
    "    return rank_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_rank = text_based_rank(embeddings.tolist()[0], response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    try:\n",
    "        image = response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"][i]['image']\n",
    "        # image = response1[\"data\"][\"Get\"][\"PinterestImages\"][i][\"top\"][0]['image']\n",
    "        # image = response1[\"data\"][\"Get\"][\"PinterestImages\"][i]['image']\n",
    "        image = Image.open(BytesIO(base64.b64decode(image.split(\",\",1)[0])))\n",
    "        image.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in new_rank.items():\n",
    "    try:\n",
    "        image = response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"][value]['image']\n",
    "        image = Image.open(BytesIO(base64.b64decode(image.split(\",\",1)[0])))\n",
    "        image.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile_top = client.data_object.get_by_id(\n",
    "    uuid=generate_uuid5(\"Female Profile 1 Top\"),\n",
    "    class_name=\"Customer_Profile\",\n",
    "    with_vector=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_top_vector = user_profile_top['vector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_popularity(products):\n",
    "    popularity_scores = {}\n",
    "    for i, product in enumerate(products):\n",
    "        popularity_scores[i] = (float(product[\"rating\"]))**2 * product[\"numberRatings\"]\n",
    "    popularity_rank = sorted(popularity_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    rank_tuples = []\n",
    "    for i, (rank, _) in enumerate(popularity_rank):\n",
    "        rank_tuples.append((i, rank))\n",
    "    return rank_tuples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_userprofile(user_top_vector, products):\n",
    "    product_scores = {}\n",
    "    for i, product in enumerate(products):\n",
    "        product_scores[i] = cosine_similarity(user_top_vector, product[\"_additional\"][\"vector\"]).tolist()[0][0]\n",
    "    product_score_rank = sorted(product_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    rank_tuples = []\n",
    "    for i, (rank, _) in enumerate(product_score_rank):\n",
    "        rank_tuples.append((i, rank))\n",
    "    return rank_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_rank = rank_by_popularity(response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rank = rank_by_userprofile(user_top_vector, response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tuples(text_rank, popularity_rank, user_rank):\n",
    "    combined_rank = {}\n",
    "    for i in range(len(text_rank)):\n",
    "        combined_rank[i] = [i, text_rank[i][1], popularity_rank[i][1], user_rank[i][1]]\n",
    "    return combined_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_tuples = combine_tuples(text_rank, popularity_rank, user_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(combine_tuples, weights):\n",
    "    fused = {}\n",
    "    for key, value in combine_tuples.items():\n",
    "        fused_score = sum(weights[i] * (1 / (val + 1)) for i, val in enumerate(value))\n",
    "        fused[key] = fused_score\n",
    "    fused_ranking = sorted(fused.items(), key=lambda x: x[1], reverse=True)\n",
    "    rrf_rank = {}\n",
    "    for i, (rank, _) in enumerate(fused_ranking):\n",
    "        rrf_rank[i] = rank\n",
    "    return rrf_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf_weights = [0.4, 0.25, 0.1, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrf_rank = reciprocal_rank_fusion(combine_tuples, rrf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in rrf_rank.items():\n",
    "    try:\n",
    "        image = response[\"data\"][\"Get\"][\"FlipkartNoSegProducts\"][value]['image']\n",
    "        image = Image.open(BytesIO(base64.b64decode(image.split(\",\",1)[0])))\n",
    "        image.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
