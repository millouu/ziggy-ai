{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from transformers import CLIPProcessor, CLIPModel, SegformerImageProcessor, AutoModelForSemanticSegmentation , AutoFeatureExtractor\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import weaviate\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:\\\\Codes\\\\ziggy-ai\\\\scraping\\\\Flipkart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(url=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipkart = open(\"flipkart_clean.json\", \"r\")\n",
    "flipkart_class = json.load(flipkart)\n",
    "flipkart.close()\n",
    "client.schema.delete_class(\"FlipkartCleanProducts\")\n",
    "client.schema.create_class(flipkart_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flipkart = open(\"flipkart_products.json\", \"r\")\n",
    "# flipkart_class = json.load(flipkart)\n",
    "# flipkart.close()\n",
    "# client.schema.delete_class(\"FlipkartProducts\")\n",
    "# client.schema.create_class(flipkart_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"patrickjohncyh/fashion-clip\"\n",
    "model = CLIPModel.from_pretrained(checkpoint)\n",
    "processor = CLIPProcessor.from_pretrained(checkpoint)\n",
    "seg_processor = SegformerImageProcessor.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "seg_model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddingsFromPath(image_path):\n",
    "\timage = Image.open(image_path)\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def getImageEmbeddings(image):\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def applyMask(image, mask):\n",
    "\timage = np.array(image)\n",
    "\tmask = np.array(mask)\n",
    "\tmask = np.stack((mask,)*3, axis=-1)\n",
    "\tresultant = image*mask\n",
    "\tresultant[mask == 0] = 255\n",
    "\treturn resultant\n",
    "\n",
    "def cropImage(image):\n",
    "\ttemp = image[:, :, ::-1].copy() \n",
    "\ttemp = temp.astype('uint8')\n",
    "\tgray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "\tthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\tcontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\tcontours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\tx,y,w,h = cv2.boundingRect(contours[0])\n",
    "\tcrop = image[y:y+h, x:x+w]\n",
    "\treturn crop\n",
    "\n",
    "def segment(image, to_mask):\n",
    "\tinputs = seg_processor(images=image, return_tensors=\"pt\")\n",
    "\toutputs = seg_model(**inputs)\n",
    "\tlogits = outputs.logits.cpu()\n",
    "\tupsampled_logits = nn.functional.interpolate(\n",
    "\t\tlogits,\n",
    "\t\tsize=image.size[::-1],\n",
    "\t\tmode=\"bilinear\",\n",
    "\t\talign_corners=False,\n",
    "\t)\n",
    "\tpred_seg = upsampled_logits.argmax(dim=1)[0]\n",
    "\tresult = []\n",
    "\tfor i in to_mask:\n",
    "\t\tmask = pred_seg.numpy().copy()\n",
    "\t\tmask[mask != i] = 0\n",
    "\t\tmask[mask == i] = 1\n",
    "\t\titem = applyMask(image, mask)\n",
    "\t\tresult.append(item)\n",
    "\treturn result\n",
    "\n",
    "def segmentAndEmbed(image_path, to_mask):\n",
    "\tresult = {}\n",
    "\timage = Image.open(image_path)\n",
    "\tfullImageEmbedding = getImageEmbeddings(image)\n",
    "\tbuffered = BytesIO()\n",
    "\timage.save(buffered, format=\"PNG\")\n",
    "\tfullImageBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\tresult[\"fullImageBase64\"] = fullImageBase64\n",
    "\tresult[\"fullImageEmbedding\"] = fullImageEmbedding\n",
    "\tsegments = segment(image, to_mask)\n",
    "\tfor i in range(len(to_mask)):\n",
    "\t\tsegmentEmbedding = getImageEmbeddings(segments[i])\n",
    "\t\tsegments[i] = Image.fromarray(np.uint8(segments[i]))\n",
    "\t\tbuffered = BytesIO()\n",
    "\t\tsegments[i].save(buffered, format=\"PNG\")\n",
    "\t\tsegmentBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\t\tresult[f\"segmentBase64_{i}\"] = segmentBase64\n",
    "\t\tresult[f\"segmentEmbedding_{i}\"] = segmentEmbedding\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    cleaned_parsed_url = parsed_url._replace(query='')\n",
    "    cleaned_url = urlunparse(cleaned_parsed_url)\n",
    "    return cleaned_url\n",
    "\n",
    "def extract_first_amount(text):\n",
    "    amount_match = re.search(r'â‚¹(\\d+)', text)\n",
    "    if amount_match:\n",
    "        first_amount = int(amount_match.group(1))\n",
    "        if first_amount == 1:\n",
    "            first_amount = 499\n",
    "        return first_amount\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_rating_and_number(string1, string2):\n",
    "    rating = string1[0:(len(string1)-len(string2))]\n",
    "    ratings_match = re.search(r'([\\d,.]+) ratings', string2)\n",
    "    if ratings_match:\n",
    "        num_ratings = int(ratings_match.group(1).replace(',', ''))\n",
    "    else:\n",
    "        num_ratings = 0\n",
    "    return rating, num_ratings\n",
    "\n",
    "def get_product_details(dict_string):\n",
    "    dict = ast.literal_eval(dict_string)\n",
    "    keys_to_check = ['Color', 'Pattern', 'Fabric', 'Fit', 'Type']\n",
    "    new_dict = {key: dict.get(key, None) for key in keys_to_check}\n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_file_names(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            try: \n",
    "                new_filename = filename.split(\"_\")[0] + \".jpg\"\n",
    "                original_path = os.path.join(folder_path, filename)\n",
    "                new_path = os.path.join(folder_path, new_filename)\n",
    "                os.rename(original_path, new_path)\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_file_names(f\"{PATH}\\\\flipkart_images\\\\Formal Pants Weaviate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{PATH}\\\\Girls Bottoms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 69 to Weaviate\n",
      "Added 70 to Weaviate\n",
      "Added 74 to Weaviate\n",
      "Added 75 to Weaviate\n",
      "Added 80 to Weaviate\n",
      "Added 81 to Weaviate\n"
     ]
    }
   ],
   "source": [
    "with client.batch(batch_size=100, num_workers=2) as batch:\n",
    "    for index, row in df.iterrows():\n",
    "        if not os.path.exists(f\"{PATH}\\\\flipkart_images\\\\Girls Bottoms Weaviate\\\\{index}.jpg\"):\n",
    "            continue\n",
    "        try:\n",
    "            ratings, num_ratings = get_rating_and_number(row[\"Rating\"], row[\"Reviews\"])\n",
    "            specification_dict = get_product_details(row[\"Specifications\"])\n",
    "            output = segmentAndEmbed(f\"{PATH}\\\\flipkart_images\\\\Girls Bottoms Weaviate\\\\{index}.jpg\", [6])\n",
    "            flipkart_obj = {\n",
    "                \"Image\" : output[\"segmentBase64_0\"],\n",
    "                # \"Image\" : output[\"fullImageBase64\"],\n",
    "                \"URL\" : clean_url(row[\"URL\"]),\n",
    "                \"Category\" : \"Girls Bottoms\",\n",
    "                \"Brand\" : row[\"Brand\"],\n",
    "                \"Product\" : row[\"Name\"],\n",
    "                \"Price\" : extract_first_amount(row[\"Price\"]),\n",
    "                \"Rating\" : ratings,\n",
    "                \"NumberRatings\" : num_ratings,\n",
    "                \"Colour\" : specification_dict[\"Color\"],\n",
    "                \"Pattern\" : specification_dict[\"Pattern\"],\n",
    "                \"Fabric\" : specification_dict[\"Fabric\"],\n",
    "                \"Fit\" : specification_dict[\"Fit\"],\n",
    "                \"Type\" : specification_dict[\"Type\"],\n",
    "                \"Specification\" : row[\"Specifications\"]\n",
    "            }\n",
    "            flipkart_uuid = batch.add_data_object(flipkart_obj, \"FlipkartCleanProducts\", vector=output[\"fullImageEmbedding\"])\n",
    "            print(f\"Added {index} to Weaviate\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while adding {index} to Weaviate: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "        if not os.path.exists(f\"{PATH}\\\\flipkart_images\\\\Girls Bottoms Weaviate\\\\{index}.jpg\"):\n",
    "            continue\n",
    "        output = segmentAndEmbed(f\"{PATH}\\\\flipkart_images\\\\Girls Bottoms Weaviate\\\\{index}.jpg\", [6])\n",
    "        image = output[\"segmentBase64_0\"]\n",
    "        image = Image.open(BytesIO(base64.b64decode(image.split(\",\",1)[0])))\n",
    "        image.save(f\"{PATH}\\\\flipkart_images\\\\Girls Bottoms Segment\\\\{index}.jpg\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
