{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import CLIPProcessor, CLIPModel, SegformerImageProcessor, AutoModelForSemanticSegmentation , AutoFeatureExtractor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import weaviate\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:\\\\Codes\\\\ziggy-ai\\\\scraping\\\\Pinterest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.Client(url=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinterest = open(\"pinterest.json\", \"r\")\n",
    "pinterest_top = open(\"pinterest_top.json\", \"r\")\n",
    "pinterest_bottom = open(\"pinterest_bottom.json\", \"r\")\n",
    "pinterest_class = json.load(pinterest)\n",
    "pinterest_top_class = json.load(pinterest_top)\n",
    "pinterest_bottom_class = json.load(pinterest_bottom)\n",
    "pinterest.close()\n",
    "pinterest_top.close()\n",
    "pinterest_bottom.close()\n",
    "\n",
    "client.schema.delete_all()\n",
    "client.schema.create_class(pinterest_top_class)\n",
    "client.schema.create_class(pinterest_bottom_class)\n",
    "client.schema.create_class(pinterest_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"patrickjohncyh/fashion-clip\"\n",
    "model = CLIPModel.from_pretrained(checkpoint)\n",
    "processor = CLIPProcessor.from_pretrained(checkpoint)\n",
    "seg_processor = SegformerImageProcessor.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")\n",
    "seg_model = AutoModelForSemanticSegmentation.from_pretrained(\"mattmdjaga/segformer_b2_clothes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageEmbeddingsFromPath(image_path):\n",
    "\timage = Image.open(image_path)\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def getImageEmbeddings(image):\n",
    "\tinputs = processor(text=[\"dummy\"] , images=image, return_tensors=\"pt\", padding=True)\n",
    "\toutputs = model(**inputs , return_dict=True)\n",
    "\treturn outputs[\"image_embeds\"]\n",
    "\n",
    "def applyMask(image, mask):\n",
    "\timage = np.array(image)\n",
    "\tmask = np.array(mask)\n",
    "\tmask = np.stack((mask,)*3, axis=-1)\n",
    "\tresultant = image*mask\n",
    "\tresultant[mask == 0] = 255\n",
    "\treturn resultant\n",
    "\n",
    "def cropImage(image):\n",
    "\ttemp = image[:, :, ::-1].copy() \n",
    "\ttemp = temp.astype('uint8')\n",
    "\tgray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n",
    "\tthresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\tcontours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\tcontours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\tx,y,w,h = cv2.boundingRect(contours[0])\n",
    "\tcrop = image[y:y+h, x:x+w]\n",
    "\treturn crop\n",
    "\n",
    "def segment(image, to_mask):\n",
    "\tinputs = seg_processor(images=image, return_tensors=\"pt\")\n",
    "\toutputs = seg_model(**inputs)\n",
    "\tlogits = outputs.logits.cpu()\n",
    "\tupsampled_logits = nn.functional.interpolate(\n",
    "\t\tlogits,\n",
    "\t\tsize=image.size[::-1],\n",
    "\t\tmode=\"bilinear\",\n",
    "\t\talign_corners=False,\n",
    "\t)\n",
    "\tpred_seg = upsampled_logits.argmax(dim=1)[0]\n",
    "\tresult = []\n",
    "\tfor i in to_mask:\n",
    "\t\tmask = pred_seg.numpy().copy()\n",
    "\t\tmask[mask != i] = 0\n",
    "\t\tmask[mask == i] = 1\n",
    "\t\titem = applyMask(image, mask)\n",
    "\t\tresult.append(item)\n",
    "\treturn result\n",
    "\n",
    "def segmentAndEmbed(image_path, to_mask):\n",
    "\tresult = {}\n",
    "\timage = Image.open(image_path)\n",
    "\tfullImageEmbedding = getImageEmbeddings(image)\n",
    "\tbuffered = BytesIO()\n",
    "\timage.save(buffered, format=\"PNG\")\n",
    "\tfullImageBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\tresult[\"fullImageBase64\"] = fullImageBase64\n",
    "\tresult[\"fullImageEmbedding\"] = fullImageEmbedding\n",
    "\tsegments = segment(image, to_mask)\n",
    "\tfor i in range(len(to_mask)):\n",
    "\t\tsegmentEmbedding = getImageEmbeddings(segments[i])\n",
    "\t\tsegments[i] = Image.fromarray(np.uint8(segments[i]))\n",
    "\t\tbuffered = BytesIO()\n",
    "\t\tsegments[i].save(buffered, format=\"PNG\")\n",
    "\t\tsegmentBase64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\t\tresult[f\"segmentBase64_{i}\"] = segmentBase64\n",
    "\t\tresult[f\"segmentEmbedding_{i}\"] = segmentEmbedding\n",
    "\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1 to Weaviate\n",
      "Added 2 to Weaviate\n",
      "Added 3 to Weaviate\n",
      "Added 4 to Weaviate\n",
      "Added 6 to Weaviate\n",
      "Added 10 to Weaviate\n",
      "Added 12 to Weaviate\n",
      "Added 14 to Weaviate\n",
      "Added 15 to Weaviate\n",
      "Added 17 to Weaviate\n",
      "Added 18 to Weaviate\n",
      "Added 19 to Weaviate\n",
      "Added 20 to Weaviate\n",
      "Added 28 to Weaviate\n",
      "Added 31 to Weaviate\n",
      "Added 32 to Weaviate\n",
      "Added 33 to Weaviate\n",
      "Added 36 to Weaviate\n",
      "Added 38 to Weaviate\n",
      "Added 39 to Weaviate\n",
      "Added 40 to Weaviate\n",
      "Added 43 to Weaviate\n",
      "Added 44 to Weaviate\n",
      "Added 46 to Weaviate\n",
      "Added 52 to Weaviate\n",
      "Added 61 to Weaviate\n",
      "Added 63 to Weaviate\n",
      "Added 65 to Weaviate\n",
      "Added 71 to Weaviate\n",
      "Added 72 to Weaviate\n",
      "Error adding 77 to Weaviate\n",
      "Error adding 80 to Weaviate\n",
      "Added 84 to Weaviate\n",
      "Added 88 to Weaviate\n",
      "Added 89 to Weaviate\n",
      "Added 91 to Weaviate\n",
      "Added 93 to Weaviate\n",
      "Added 97 to Weaviate\n",
      "Added 99 to Weaviate\n",
      "Added 100 to Weaviate\n",
      "Added 104 to Weaviate\n",
      "Added 105 to Weaviate\n",
      "Added 107 to Weaviate\n",
      "Added 113 to Weaviate\n",
      "Added 115 to Weaviate\n",
      "Added 120 to Weaviate\n",
      "Added 121 to Weaviate\n",
      "Added 123 to Weaviate\n",
      "Added 137 to Weaviate\n",
      "Added 139 to Weaviate\n",
      "Added 144 to Weaviate\n",
      "Added 145 to Weaviate\n",
      "Added 149 to Weaviate\n",
      "Added 152 to Weaviate\n",
      "Added 154 to Weaviate\n",
      "Added 168 to Weaviate\n",
      "Added 170 to Weaviate\n",
      "Added 171 to Weaviate\n",
      "Added 176 to Weaviate\n",
      "Added 178 to Weaviate\n",
      "Added 193 to Weaviate\n",
      "Added 196 to Weaviate\n",
      "Added 200 to Weaviate\n",
      "Added 217 to Weaviate\n",
      "Added 218 to Weaviate\n",
      "Added 219 to Weaviate\n",
      "Added 224 to Weaviate\n",
      "Added 234 to Weaviate\n",
      "Added 240 to Weaviate\n",
      "Added 244 to Weaviate\n",
      "Added 249 to Weaviate\n",
      "Added 257 to Weaviate\n",
      "Added 263 to Weaviate\n",
      "Added 266 to Weaviate\n",
      "Added 280 to Weaviate\n",
      "Added 281 to Weaviate\n",
      "Added 288 to Weaviate\n",
      "Added 307 to Weaviate\n",
      "Error adding 314 to Weaviate\n",
      "Added 320 to Weaviate\n",
      "Added 321 to Weaviate\n",
      "Added 325 to Weaviate\n",
      "Added 339 to Weaviate\n",
      "Added 341 to Weaviate\n",
      "Added 348 to Weaviate\n",
      "Added 352 to Weaviate\n",
      "Error adding 353 to Weaviate\n",
      "Added 360 to Weaviate\n",
      "Added 361 to Weaviate\n",
      "Added 363 to Weaviate\n",
      "Added 376 to Weaviate\n",
      "Added 382 to Weaviate\n",
      "Added 383 to Weaviate\n",
      "Added 384 to Weaviate\n",
      "Added 385 to Weaviate\n",
      "Added 386 to Weaviate\n",
      "Added 391 to Weaviate\n",
      "Added 392 to Weaviate\n",
      "Added 393 to Weaviate\n",
      "Added 398 to Weaviate\n",
      "Added 401 to Weaviate\n",
      "Added 407 to Weaviate\n",
      "Added 411 to Weaviate\n",
      "Added 412 to Weaviate\n",
      "Added 414 to Weaviate\n",
      "Added 418 to Weaviate\n",
      "Added 419 to Weaviate\n",
      "Added 422 to Weaviate\n",
      "Added 425 to Weaviate\n",
      "Added 435 to Weaviate\n",
      "Added 441 to Weaviate\n",
      "Added 447 to Weaviate\n",
      "Added 448 to Weaviate\n",
      "Added 450 to Weaviate\n",
      "Added 455 to Weaviate\n",
      "Added 465 to Weaviate\n",
      "Added 466 to Weaviate\n",
      "Added 468 to Weaviate\n",
      "Added 471 to Weaviate\n",
      "Added 475 to Weaviate\n",
      "Added 476 to Weaviate\n",
      "Added 478 to Weaviate\n",
      "Added 480 to Weaviate\n",
      "Added 483 to Weaviate\n",
      "Added 489 to Weaviate\n",
      "Added 496 to Weaviate\n",
      "Added 497 to Weaviate\n",
      "Added 498 to Weaviate\n",
      "Added 501 to Weaviate\n",
      "Added 502 to Weaviate\n",
      "Added 506 to Weaviate\n",
      "Added 507 to Weaviate\n",
      "Added 511 to Weaviate\n",
      "Added 514 to Weaviate\n",
      "Added 519 to Weaviate\n",
      "Added 521 to Weaviate\n",
      "Added 522 to Weaviate\n",
      "Added 527 to Weaviate\n",
      "Added 528 to Weaviate\n",
      "Added 531 to Weaviate\n",
      "Error adding 532 to Weaviate\n",
      "Added 534 to Weaviate\n",
      "Added 540 to Weaviate\n",
      "Added 541 to Weaviate\n",
      "Added 545 to Weaviate\n",
      "Added 546 to Weaviate\n",
      "Added 547 to Weaviate\n",
      "Added 551 to Weaviate\n",
      "Added 552 to Weaviate\n",
      "Added 558 to Weaviate\n",
      "Added 561 to Weaviate\n",
      "Error adding 562 to Weaviate\n",
      "Added 567 to Weaviate\n",
      "Added 579 to Weaviate\n",
      "Added 580 to Weaviate\n",
      "Added 589 to Weaviate\n",
      "Added 591 to Weaviate\n",
      "Added 593 to Weaviate\n",
      "Added 599 to Weaviate\n",
      "Added 601 to Weaviate\n",
      "Added 609 to Weaviate\n",
      "Added 630 to Weaviate\n",
      "Added 632 to Weaviate\n",
      "Added 636 to Weaviate\n",
      "Added 657 to Weaviate\n",
      "Added 658 to Weaviate\n",
      "Added 671 to Weaviate\n",
      "Added 679 to Weaviate\n",
      "Added 680 to Weaviate\n",
      "Added 682 to Weaviate\n",
      "Added 686 to Weaviate\n",
      "Added 688 to Weaviate\n",
      "Added 689 to Weaviate\n",
      "Added 705 to Weaviate\n",
      "Added 707 to Weaviate\n",
      "Added 724 to Weaviate\n",
      "Added 726 to Weaviate\n",
      "Added 728 to Weaviate\n",
      "Added 733 to Weaviate\n",
      "Added 735 to Weaviate\n",
      "Added 740 to Weaviate\n",
      "Added 744 to Weaviate\n",
      "Added 750 to Weaviate\n",
      "Added 756 to Weaviate\n",
      "Added 757 to Weaviate\n",
      "Error adding 771 to Weaviate\n",
      "Added 772 to Weaviate\n",
      "Added 783 to Weaviate\n",
      "Error adding 789 to Weaviate\n",
      "Added 790 to Weaviate\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{PATH}\\\\mens_formal.csv\")\n",
    "with client.batch(batch_size=100, num_workers=2) as batch:\n",
    "    for index, row in df.iterrows():\n",
    "        if os.path.exists(f\"{PATH}\\\\mens_formal\\\\image_{index}.jpg\"):\n",
    "            try:\n",
    "                output = segmentAndEmbed(f\"{PATH}\\\\mens_formal\\\\image_{index}.jpg\", [4, 6])\n",
    "                pinterest_obj = {\n",
    "                    \"category\" : \"mens_traditional\",\n",
    "                    \"description\" : row[\"Image Alt Text\"],\n",
    "                    \"image\" : output[\"fullImageBase64\"]\n",
    "                }\n",
    "                pinterest_uuid = batch.add_data_object(pinterest_obj, \"PinterestImages\", vector=output[\"fullImageEmbedding\"])\n",
    "                pinterest_top_uuid = batch.add_data_object({\"image\" : output[\"segmentBase64_0\"]}, \"PinterestTop\", vector=output[\"segmentEmbedding_0\"])\n",
    "                pinterest_bottom_uuid = batch.add_data_object({\"image\" : output[\"segmentBase64_1\"]}, \"PinterestBottom\", vector=output[\"segmentEmbedding_1\"])\n",
    "                batch.add_reference(from_object_class_name=\"PinterestImages\", to_object_class_name=\"PinterestTop\", from_object_uuid=pinterest_uuid, to_object_uuid=pinterest_top_uuid, from_property_name=\"top\")\n",
    "                batch.add_reference(from_object_class_name=\"PinterestImages\", to_object_class_name=\"PinterestBottom\", from_object_uuid=pinterest_uuid, to_object_uuid=pinterest_bottom_uuid, from_property_name=\"bottom\")\n",
    "                print(f\"Added {index} to Weaviate\")\n",
    "            except:\n",
    "                print(f\"Error adding {index} to Weaviate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
